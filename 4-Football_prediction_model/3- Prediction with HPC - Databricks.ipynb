{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 3: Prediction Model (WITH PCA features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StandardScaler, PCA, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import FloatType, ArrayType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# For scikit-learn models (we'll use these with Spark)\n",
    "from sklearn.preprocessing import StandardScaler as SklearnStandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as SklearnRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"FootballPrediction\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df_pandas = spark.read.csv(\"/FileStore/df.csv\", header = True, inferSchema = True, sep=';')\n",
    "df = spark.createDataFrame(df_pandas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the most important features from PCA\n",
    "selected_features = [\n",
    "    'PC1',\n",
    "    'PC2',\n",
    "    'PC3',\n",
    "    'PC4',\n",
    "    'PC5',\n",
    "    'PC6'\n",
    "]\n",
    "\n",
    "# Create feature vector assembler\n",
    "assembler = VectorAssembler(inputCols=selected_features, outputCol=\"features\")\n",
    "\n",
    "# Create a scaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", \n",
    "                       withStd=True, withMean=True)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Dataset shape: {df.count()} rows, {len(df.columns)} columns\")\n",
    "df.groupBy(\"HomeWin\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Create a pipeline for preprocessing\n",
    "preprocessing_pipeline = Pipeline(stages=[\n",
    "    assembler,\n",
    "    scaler\n",
    "])\n",
    "\n",
    "# Fit preprocessing on training data\n",
    "preprocessing_model = preprocessing_pipeline.fit(train_df)\n",
    "\n",
    "# Transform both training and testing data\n",
    "train_processed = preprocessing_model.transform(train_df)\n",
    "test_processed = preprocessing_model.transform(test_df)\n",
    "\n",
    "# Cache the processed datasets for faster access\n",
    "train_processed.cache()\n",
    "test_processed.cache()\n",
    "\n",
    "# Create pandas dataframes for scikit-learn models\n",
    "train_pd = train_processed.select(\"scaledFeatures\", \"HomeWin\", \"B365H\", \"B365H_prob\").toPandas()\n",
    "test_pd = test_processed.select(\"scaledFeatures\", \"HomeWin\", \"B365H\", \"B365H_prob\").toPandas()\n",
    "\n",
    "# Extract features and labels\n",
    "X_train = np.array([x.toArray() for x in train_pd[\"scaledFeatures\"]])\n",
    "y_train = train_pd[\"HomeWin\"].values\n",
    "X_test = np.array([x.toArray() for x in test_pd[\"scaledFeatures\"]])\n",
    "y_test = test_pd[\"HomeWin\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train and evaluate multiple machine learning models\n",
    "\n",
    " We will test 4 different models:\n",
    "\n",
    " - Decision Tree: A simple tree-based model\n",
    "\n",
    " - Random Forest: An ensemble of decision trees\n",
    "\n",
    " - Support Vector Machine (SVM): A powerful classifier that works well with scaled data\n",
    "\n",
    " - K-Nearest Neighbors (KNN): A distance-based classifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Spark ML models\n",
    "spark_lr = LogisticRegression(featuresCol=\"scaledFeatures\", labelCol=\"HomeWin\", maxIter=100)\n",
    "spark_dt = DecisionTreeClassifier(featuresCol=\"scaledFeatures\", labelCol=\"HomeWin\")\n",
    "spark_rf = RandomForestClassifier(featuresCol=\"scaledFeatures\", labelCol=\"HomeWin\", \n",
    "                                 numTrees=100, subsamplingRate=0.8)\n",
    "\n",
    "# Initialize scikit-learn models\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# Create evaluators for Spark models\n",
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"HomeWin\", rawPredictionCol=\"rawPrediction\")\n",
    "multi_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"HomeWin\", predictionCol=\"prediction\")\n",
    "\n",
    "# Lists to store metrics\n",
    "model_names = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "trained_models = {}\n",
    "\n",
    "# Function to evaluate Spark models\n",
    "def evaluate_spark_model(model, name):\n",
    "    model_fitted = model.fit(train_processed)\n",
    "    predictions = model_fitted.transform(test_processed)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = multi_evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "    precision = multi_evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions)\n",
    "    recall = multi_evaluator.setMetricName(\"weightedRecall\").evaluate(predictions)\n",
    "    f1 = multi_evaluator.setMetricName(\"f1\").evaluate(predictions)\n",
    "    auc_score = binary_evaluator.evaluate(predictions)\n",
    "    \n",
    "    # Store metrics\n",
    "    model_names.append(name)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    auc_scores.append(auc_score)\n",
    "    trained_models[name] = model_fitted\n",
    "    \n",
    "    return model_fitted, predictions\n",
    "\n",
    "# Function to evaluate scikit-learn models\n",
    "def evaluate_sklearn_model(model, name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get probabilities\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_probs = model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        y_probs = model.decision_function(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Store metrics\n",
    "    model_names.append(name)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    auc_scores.append(roc_auc)\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    return model, y_probs\n",
    "\n",
    "# Evaluate Spark models\n",
    "lr_model, lr_preds = evaluate_spark_model(spark_lr, \"Logistic Regression\")\n",
    "dt_model, dt_preds = evaluate_spark_model(spark_dt, \"Decision Tree\")\n",
    "rf_model, rf_preds = evaluate_spark_model(spark_rf, \"Random Forest\")\n",
    "\n",
    "# Evaluate scikit-learn models\n",
    "svm_fitted, svm_probs = evaluate_sklearn_model(svm_model, \"SVM\")\n",
    "knn_fitted, knn_probs = evaluate_sklearn_model(knn_model, \"KNN\")\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions, \n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC': auc_scores\n",
    "})\n",
    "\n",
    "# Style the DataFrame\n",
    "styled_df = results_df.style\\\n",
    "    .background_gradient(cmap='RdYlGn')\\\n",
    "    .format({\n",
    "        'Accuracy': '{:.4f}',\n",
    "        'Precision': '{:.4f}',\n",
    "        'Recall': '{:.4f}',\n",
    "        'F1 Score': '{:.4f}',\n",
    "        'AUC': '{:.4f}'\n",
    "    })\\\n",
    "    .set_caption('Model Performance Comparison')\n",
    "\n",
    "display(styled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to get probabilities from Spark models\n",
    "def get_spark_model_probs(model_name):\n",
    "    model = trained_models[model_name]\n",
    "    predictions = model.transform(test_processed)\n",
    "    if model_name == \"Logistic Regression\":\n",
    "        # For Logistic Regression, use probability column\n",
    "        probs_df = predictions.select(\"HomeWin\", \"probability\").toPandas()\n",
    "        probs = np.array([p[1] for p in probs_df.probability])\n",
    "    else:\n",
    "        # For tree-based models, use prediction column\n",
    "        probs_df = predictions.select(\"HomeWin\", \"probability\").toPandas()\n",
    "        probs = np.array([p[1] for p in probs_df.probability])\n",
    "    return probs\n",
    "\n",
    "# Get probabilities for positive class from Spark models\n",
    "rf_probs = get_spark_model_probs(\"Random Forest\")\n",
    "lr_probs = get_spark_model_probs(\"Logistic Regression\")\n",
    "\n",
    "# Get Bet365's implied probability for home win\n",
    "bet365_probs = test_pd['B365H_prob'].values\n",
    "\n",
    "# Calculate ROC curves\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_probs)\n",
    "bet365_fpr, bet365_tpr, _ = roc_curve(y_test, bet365_probs)\n",
    "\n",
    "# Calculate AUC scores\n",
    "rf_auc = auc(rf_fpr, rf_tpr)\n",
    "lr_auc = auc(lr_fpr, lr_tpr)\n",
    "svm_auc = auc(svm_fpr, svm_tpr)\n",
    "bet365_auc = auc(bet365_fpr, bet365_tpr)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rf_fpr, rf_tpr, label=f'Random Forest (AUC = {rf_auc:.3f})')\n",
    "plt.plot(lr_fpr, lr_tpr, label=f'Logistic Regression (AUC = {lr_auc:.3f})')\n",
    "plt.plot(svm_fpr, svm_tpr, label=f'SVM (AUC = {svm_auc:.3f})')\n",
    "plt.plot(bet365_fpr, bet365_tpr, color='black', linestyle='-', linewidth=2, \n",
    "         label=f'Bet365 Implied (AUC = {bet365_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print AUC scores\n",
    "print(\"\\nAUC Scores:\")\n",
    "print(f\"Random Forest: {rf_auc:.4f}\")\n",
    "print(f\"Logistic Regression: {lr_auc:.4f}\")\n",
    "print(f\"SVM: {svm_auc:.4f}\")\n",
    "print(f\"Bet365 Implied: {bet365_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the MLPClassifier\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),  # Two hidden layers with 100 and 50 neurons\n",
    "    activation='relu',             # ReLU activation function\n",
    "    solver='adam',                 # Adam optimizer\n",
    "    alpha=0.0001,                  # L2 regularization term\n",
    "    batch_size='auto',             # Automatic batch size\n",
    "    learning_rate='adaptive',      # Adaptive learning rate\n",
    "    max_iter=1000,                 # Maximum number of iterations\n",
    "    early_stopping=True,           # Use early stopping\n",
    "    validation_fraction=0.1,       # 10% of training data for validation\n",
    "    n_iter_no_change=10,           # Stop if no improvement after 10 iterations\n",
    "    random_state=42                # For reproducibility\n",
    ")\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "mlp_probs = mlp.predict_proba(X_test)[:, 1]\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calculate ROC curve and AUC score\n",
    "mlp_fpr, mlp_tpr, _ = roc_curve(y_test, mlp_probs)\n",
    "mlp_auc = auc(mlp_fpr, mlp_tpr)\n",
    "\n",
    "# Calculate metrics for MLP\n",
    "mlp_accuracy = accuracy_score(y_test, mlp_pred)\n",
    "mlp_precision = precision_score(y_test, mlp_pred)\n",
    "mlp_recall = recall_score(y_test, mlp_pred)\n",
    "mlp_f1 = f1_score(y_test, mlp_pred)\n",
    "\n",
    "# Store the MLP model for later use\n",
    "trained_models['Neural Network'] = mlp\n",
    "\n",
    "# Calculate metrics for Bet365 implied probabilities\n",
    "# Find optimal threshold for Bet365 classification (maximize f1-score)\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "best_f1 = 0\n",
    "best_threshold = 0.5  # default threshold\n",
    "\n",
    "for threshold in thresholds:\n",
    "    bet365_pred = (bet365_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, bet365_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Use best threshold to make predictions\n",
    "bet365_pred = (bet365_probs >= best_threshold).astype(int)\n",
    "bet365_accuracy = accuracy_score(y_test, bet365_pred)\n",
    "bet365_precision = precision_score(y_test, bet365_pred)\n",
    "bet365_recall = recall_score(y_test, bet365_pred)\n",
    "bet365_f1 = f1_score(y_test, bet365_pred)\n",
    "\n",
    "# Add MLP and Bet365 to the results DataFrame\n",
    "results_df_with_all = pd.DataFrame({\n",
    "    'Model': model_names + ['Neural Network', 'Bet365 Implied'],\n",
    "    'Accuracy': accuracies + [mlp_accuracy, bet365_accuracy],\n",
    "    'Precision': precisions + [mlp_precision, bet365_precision], \n",
    "    'Recall': recalls + [mlp_recall, bet365_recall],\n",
    "    'F1 Score': f1_scores + [mlp_f1, bet365_f1],\n",
    "    'AUC': auc_scores + [mlp_auc, bet365_auc]\n",
    "})\n",
    "\n",
    "# Style the DataFrame\n",
    "styled_df_with_all = results_df_with_all.style\\\n",
    "    .background_gradient(cmap='RdYlGn')\\\n",
    "    .format({\n",
    "        'Accuracy': '{:.4f}',\n",
    "        'Precision': '{:.4f}',\n",
    "        'Recall': '{:.4f}',\n",
    "        'F1 Score': '{:.4f}',\n",
    "        'AUC': '{:.4f}'\n",
    "    })\\\n",
    "    .set_caption('Model Performance Comparison (Including Neural Network and Bet365)')\n",
    "\n",
    "display(styled_df_with_all)\n",
    "\n",
    "# Add MLP to the ROC curve comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rf_fpr, rf_tpr, color='#6495ED', label=f'Random Forest (AUC = {rf_auc:.3f})')\n",
    "plt.plot(lr_fpr, lr_tpr, color='#4169E1', label=f'Logistic Regression (AUC = {lr_auc:.3f})')\n",
    "plt.plot(svm_fpr, svm_tpr, color='#6495ED', label=f'SVM (AUC = {svm_auc:.3f})')\n",
    "plt.plot(mlp_fpr, mlp_tpr, color='red', label=f'Neural Network (AUC = {mlp_auc:.3f})')\n",
    "plt.plot(bet365_fpr, bet365_tpr, color='black', linestyle='-', linewidth=2, \n",
    "         label=f'Bet365 Implied (AUC = {bet365_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print AUC scores\n",
    "print(\"\\nAUC Scores:\")\n",
    "print(f\"Random Forest: {rf_auc:.4f}\")\n",
    "print(f\"Logistic Regression: {lr_auc:.4f}\")\n",
    "print(f\"SVM: {svm_auc:.4f}\")\n",
    "print(f\"Neural Network: {mlp_auc:.4f}\")\n",
    "print(f\"Bet365 Implied: {bet365_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Extra: Using the model predictions to build a betting strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Placing a bet for the Home Team Win whenever the model probability is greather than the Bet365 Implied probability multiplied by a minimum margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betting Strategy Simulation \n",
    "# This section is not parallelized as it depends on sequential betting\n",
    "\n",
    "# Min Bet Margin \n",
    "min_bet_margin = 0.05\n",
    "\n",
    "# Get the odds\n",
    "bet365_odds = test_pd['B365H'].values\n",
    "\n",
    "# Define random seeds for different random betting strategies\n",
    "random_seeds = [42, 123, 456]\n",
    "\n",
    "# Initialize results dictionary\n",
    "betting_results = {\n",
    "    'Random Forest': {'bets': 0, 'wins': 0, 'losses': 0, 'profit': 0, 'roi': 0},\n",
    "    'Logistic Regression': {'bets': 0, 'wins': 0, 'losses': 0, 'profit': 0, 'roi': 0},\n",
    "    'SVM': {'bets': 0, 'wins': 0, 'losses': 0, 'profit': 0, 'roi': 0},\n",
    "    'Neural Network': {'bets': 0, 'wins': 0, 'losses': 0, 'profit': 0, 'roi': 0},\n",
    "    'Random Selection 1': {'bets': 0, 'wins': 0, 'losses': 0, 'profit': 0, 'roi': 0},\n",
    "    'Random Selection 2': {'bets': 0, 'wins': 0, 'losses': 0, 'profit': 0, 'roi': 0},\n",
    "    'Random Selection 3': {'bets': 0, 'wins': 0, 'losses': 0, 'profit': 0, 'roi': 0}\n",
    "}\n",
    "\n",
    "# Betting parameters\n",
    "initial_bankroll = 1000  # Starting with $1000\n",
    "fixed_stake = 10         # Fixed stake of $10 per bet\n",
    "\n",
    "# Helper function to process a bet regardless of strategy\n",
    "def process_bet(model_name, index, bankroll):\n",
    "    stake = fixed_stake\n",
    "    betting_results[model_name]['bets'] += 1\n",
    "    \n",
    "    # Check if it's a win (home team won)\n",
    "    if y_test[index] == 1:\n",
    "        # Win: get stake back plus winnings\n",
    "        winnings = stake * (bet365_odds[index] - 1)\n",
    "        bankroll += winnings\n",
    "        betting_results[model_name]['wins'] += 1\n",
    "        return bankroll, (index, stake, winnings, bankroll)\n",
    "    else:\n",
    "        # Loss: lose stake\n",
    "        bankroll -= stake\n",
    "        betting_results[model_name]['losses'] += 1\n",
    "        return bankroll, (index, stake, -stake, bankroll)\n",
    "\n",
    "# Function to simulate betting for ML models\n",
    "def simulate_betting(model_probs, model_name):\n",
    "    bankroll = initial_bankroll\n",
    "    bet_history = []\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        # Only bet when model probability is higher than bookmaker's implied probability\n",
    "        if model_probs[i] > bet365_probs[i]*(1 + min_bet_margin) and model_probs[i] > 0.5:\n",
    "            bankroll, bet_record = process_bet(model_name, i, bankroll)\n",
    "            bet_history.append(bet_record)\n",
    "    \n",
    "    # Calculate profit and ROI\n",
    "    betting_results[model_name]['profit'] = bankroll - initial_bankroll\n",
    "    betting_results[model_name]['roi'] = (bankroll / initial_bankroll - 1) * 100\n",
    "    \n",
    "    return bet_history\n",
    "\n",
    "# Function to simulate random betting strategy\n",
    "def simulate_random_betting(model_name, seed=42):\n",
    "    bankroll = initial_bankroll\n",
    "    bet_history = []\n",
    "    \n",
    "    # Randomly select matches to bet on\n",
    "    np.random.seed(seed)\n",
    "    bet_indices = np.random.choice(len(y_test), size=len(y_test)//6, replace=False)\n",
    "    \n",
    "    for i in bet_indices:\n",
    "        bankroll, bet_record = process_bet(model_name, i, bankroll)\n",
    "        bet_history.append(bet_record)\n",
    "    \n",
    "    # Calculate profit and ROI\n",
    "    betting_results[model_name]['profit'] = bankroll - initial_bankroll\n",
    "    betting_results[model_name]['roi'] = (bankroll / initial_bankroll - 1) * 100\n",
    "    \n",
    "    return bet_history\n",
    "\n",
    "# Run simulations\n",
    "model_histories = {\n",
    "    'Random Forest': simulate_betting(rf_probs, 'Random Forest'),\n",
    "    'Logistic Regression': simulate_betting(lr_probs, 'Logistic Regression'),\n",
    "    'SVM': simulate_betting(svm_probs, 'SVM'),\n",
    "    'Neural Network': simulate_betting(mlp_probs, 'Neural Network')\n",
    "}\n",
    "\n",
    "# Run random betting simulations with different seeds\n",
    "random_bet_histories = []\n",
    "for i, seed in enumerate(random_seeds):\n",
    "    model_name = f'Random Selection {i+1}'\n",
    "    random_bet_histories.append(simulate_random_betting(model_name, seed=seed))\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBetting Strategy Results:\")\n",
    "for model, results in betting_results.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    win_rate_str = f\"Wins: {results['wins']} ({results['wins']/results['bets']*100:.2f}% win rate)\" if results['bets'] > 0 else \"Wins: 0 (0.00% win rate)\"\n",
    "    print(win_rate_str)\n",
    "    print(f\"Profit: ${results['profit']:.2f}\")\n",
    "    print(f\"ROI: {results['roi']:.2f}%\")\n",
    "\n",
    "# Plot bankroll evolution with custom colors\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Define color scheme\n",
    "orange_shades = ['#ff7f0e', '#FFA500', '#FF8C00']  # Shades of orange for ML models\n",
    "red_color = '#d62728'  # Red for deep learning model\n",
    "purple_shades = ['#9467bd', '#8674A1', '#7B68EE']  # Shades of purple for random selections\n",
    "\n",
    "# Plot ML and Neural Network model bankrolls\n",
    "for i, (model_name, history) in enumerate(model_histories.items()):\n",
    "    if history:\n",
    "        if model_name == 'Neural Network':\n",
    "            color = red_color\n",
    "        else:\n",
    "            color = orange_shades[i % len(orange_shades)]\n",
    "        \n",
    "        bankroll = [initial_bankroll] + [bet[3] for bet in history]\n",
    "        plt.plot(range(len(bankroll)), bankroll, label=model_name, color=color)\n",
    "\n",
    "# Plot random selection bankrolls\n",
    "for i, history in enumerate(random_bet_histories):\n",
    "    if history:\n",
    "        random_bankroll = [initial_bankroll] + [bet[3] for bet in history]\n",
    "        plt.plot(range(len(random_bankroll)), random_bankroll, \n",
    "                 label=f'Random Selection {i+1}', \n",
    "                 color=purple_shades[i], \n",
    "                 linestyle='--')\n",
    "\n",
    "plt.axhline(y=initial_bankroll, color='green', linestyle='--', label='Initial Bankroll')\n",
    "plt.xlabel('Number of Bets')\n",
    "plt.ylabel('Bankroll ($)')\n",
    "plt.title('Bankroll Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame with betting results for better visualization\n",
    "results_table = {\n",
    "    'Model Type': [],\n",
    "    'Model': [],\n",
    "    'Total Bets': [],\n",
    "    'Win Rate (%)': [],\n",
    "    'Profit ($)': [],\n",
    "    'ROI (%)': []\n",
    "}\n",
    "\n",
    "for model, results in betting_results.items():\n",
    "    # Determine model type based on model name\n",
    "    model_type = 'Random Selection' if 'Random Selection' in model else ('Deep Learning' if model == 'Neural Network' else 'Machine Learning')\n",
    "    \n",
    "    # Calculate win rate safely\n",
    "    win_rate = results['wins']/results['bets']*100 if results['bets'] > 0 else 0\n",
    "    \n",
    "    # Add all data to the results table\n",
    "    results_table['Model Type'].append(model_type)\n",
    "    results_table['Model'].append(model)\n",
    "    results_table['Total Bets'].append(results['bets'])\n",
    "    results_table['Win Rate (%)'].append(win_rate)\n",
    "    results_table['Profit ($)'].append(results['profit'])\n",
    "    results_table['ROI (%)'].append(results['roi'])\n",
    "\n",
    "# Convert to DataFrame and style it\n",
    "results_df = pd.DataFrame(results_table)\n",
    "styled_df = results_df.style\\\n",
    "    .background_gradient(subset=['Win Rate (%)', 'Profit ($)', 'ROI (%)'], cmap='RdYlGn')\\\n",
    "    .set_properties(**{'text-align': 'center'})\\\n",
    "    .format({\n",
    "        'Win Rate (%)': '{:.2f}',\n",
    "        'Profit ($)': '{:.2f}',\n",
    "        'ROI (%)': '{:.2f}'\n",
    "    })\\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'th',\n",
    "        'props': [('background-color', '#f2f2f2'), \n",
    "                  ('color', 'black'),\n",
    "                  ('font-weight', 'bold'),\n",
    "                  ('text-align', 'center')]\n",
    "    }])\\\n",
    "    .set_caption('Betting Strategy Performance Comparison')\n",
    "\n",
    "display(styled_df)\n",
    "\n",
    "# Stop the Spark session when done\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
